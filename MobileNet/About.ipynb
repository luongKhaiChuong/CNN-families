{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e5bee1",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu:\n",
    "MobileNet là một họ kiến trúc CNN được phát triển bởi Google, với mục tiêu tối ưu hóa cho các thiết bị di động và hệ thống có tài nguyên hạn chế như điện thoại thông minh, thiết bị IoT hay vi xử lý nhúng. Ý tưởng là tách các kênh trong 1 ảnh ra, học riêng các feature trong từng kênh, sau đó mới gộp lại. Các mô hình trong họ MobileNet giúp giảm thiểu số lượng parameters và lượng phép tính (FLOPs), đồng thời vẫn duy trì độ chính xác cao trong các bài toán thị giác máy tính.\n",
    "\n",
    "Các ứng dụng phổ biến:\n",
    "- Phân loại hình ảnh\n",
    "- Nhận diện đối tượng\n",
    "- Nhận diện khuôn mặt\n",
    "- Phát hiện tư thế\n",
    "- Sử dụng trong các framework như: TensorFlow Lite, CoreML, ONNX,...\n",
    "\n",
    "# 2. Vấn đề:\n",
    "Trong CNN truyền thống, một lớp convolution chuẩn sử dụng một tập kernel 3×3 (hoặc 5×5) để trích xuất đặc trưng từ toàn bộ ảnh đầu vào, đồng thời trộn thông tin giữa các kênh màu để tạo ra một đặc trưng tổng hợp. Cách hoạt động của nó gây ra 3 vấn đề chính:\n",
    "\n",
    "### 1. FLOPs:\n",
    "FLOPs cho 1 lớp convolution truyền thống:\n",
    "$$FLOPs=H*W*K^2*M*N$$\n",
    "Với:\n",
    "- M: số kênh đầu vào\n",
    "- N: số kênh đầu ra\n",
    "- K: kích thước kernel (thường là 3)\n",
    "- H × W: kích thước không gian đầu vào\n",
    "\n",
    "Điều này rất tốn kém, đặc biệt khi số kênh lớn. Lấy ví dụ 1 ảnh đầu vào 224x224x3, N = 64, K = 3:\n",
    "\n",
    "$$FLOPs=224*224*3^2*3*64 \\approx 86000000$$\n",
    "\n",
    "### 2. Parameters:\n",
    "Số parameter cũng bị ảnh hưởng nghiêm trọng. Ta có công thức:\n",
    "$$\\text{layer param} = K^2*M*N$$\n",
    "\n",
    "Ví dụ với $K=3, M=128, N=256$, ta đã có:\n",
    "$$\\text{layer param} = 3^2*128*256 = 294912$$\n",
    "\n",
    "Đây là số lượng tham số chỉ cho 1 lớp CNN. Vấn đề này khiến bộ nhớ và thời gian tải mô hình tăng theo.\n",
    "\n",
    "### 3. Ép 1 bộ lọc làm 2 nhiệm vụ cùng lúc:\n",
    "Khi ta áp dụng cùng 1 kernel cho toàn bộ không gian ảnh, bộ lọc phải làm cùng lúc 2 việc:\n",
    "- Học cách trích xuất các feature không gian (edge, texture,...)\n",
    "- Học cách kết hợp thông tin giữa các kênh màu\n",
    "\n",
    "Việc này khi tách ra sẽ giảm rất nhiều độ phức tạp tính toán.\n",
    "\n",
    "# 3. Giải pháp đề xuất:\n",
    "### 1. Intuition đằng sau giải pháp: \n",
    "Không phải phép conv nào cũng cần học quan hệ giữa các kênh cùng 1 lúc. Các feature trong những kênh riêng biệt, rồi mới kết hợp lại như trong xử lý ảnh cổ điển (dùng kernel như Sobel để lọc riêng từng kênh, sau đó mới gộp thông tin)\n",
    "### 2. Depthwise seperable convolution:\n",
    "Thay vì dùng 1 bước convolution 3D thông thường ($H*W*N$), ta thay bằng 2 bước riêng biệt:\n",
    "- Depthwise convolution (lọc không gian):\n",
    "    - 1 filter 2D (thường là $3*3$) được áp dụng cho MỖI KÊNH đầu vào.\n",
    "    - Không làm thay đổi số kênh, chỉ áp dụng filter cho từng kênh.\n",
    "    \n",
    "    VD: ảnh inp có 3 kênh màu -> tensor vẫn có 3 kênh nhờ áp dụng kernel $3*3$ cho mỗi kênh input.\n",
    "- Pointwise convolution (kết hợp kênh):\n",
    "    - Dùng filter $1*1*K_{input}$ để kết hợp các giá trị tại cùng vị trí không gian nhưng trên nhiều kênh khác nhau.\n",
    "    - Đây là giai đoạn mô hình học mối quan hệ giữa các kênh như conv bình thường. \n",
    "    \n",
    "    VD: 3 kênh đầu vào (sau deptwise conv) -> 64 kênh output bằng cách dùng 64 kernel $1*1*3$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
